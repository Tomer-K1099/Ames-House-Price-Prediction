# Ames-House-Price-Prediction
**Project Overview**: This project addresses the challenge of predicting house prices in Ames, Iowa, using multiple regression algorithms and advanced machine learning techniques. The goal was to build a robust model capable of accurately estimating property values, which involved a comprehensive process of data preprocessing, feature engineering, and model optimization. The project employed six different regression models and analyzed their performance using metrics such as Root Mean Squared Error (RMSE) and R² scores.

### Key Highlights and Academic Value:
#### Data Cleansing Process:
The project begins with a meticulous data cleansing phase, addressing common data quality issues that could negatively impact model performance. Given the nature of real-world datasets, many attributes in the house price dataset were incomplete, containing missing values or inconsistencies that needed to be resolved.
#### Data Analysis: 
Once the data was cleansed, an in-depth exploratory data analysis (EDA) was performed to uncover hidden patterns and relationships
#### Algorithm Diversity:
The project explores a range of regression techniques, from classical methods such as Locally Weighted Linear Regression (LWLR) and K-Nearest Neighbors (KNN) to more complex ensemble methods like Random Forest and Gradient Boosting. This diversity showcases a thorough understanding of different approaches and their trade-offs in predictive modeling.
#### Principal Component Analysis (PCA):
A significant focus was placed on dimensionality reduction using PCA to assess its impact on model performance. By reducing the feature space, the project demonstrates how PCA can help eliminate redundancy and noise, enhancing model interpretability and efficiency.
#### Model Evaluation and Hyperparameter Tuning:
The project leverages Recursive Feature Elimination with Cross-Validation (RFECV) and Grid Search CV for hyperparameter tuning. These techniques highlight the careful consideration given to optimizing model performance while avoiding overfitting.
#### Ensemble Techniques and Regularization:
The use of ElasticNet regularization (a combination of Lasso and Ridge) was particularly effective in this context, allowing the model to balance feature selection and penalization. The project’s focus on ensemble methods like Random Forest and Gradient Boosting further underlines the emphasis on improving stability and predictive power.
#### Results Analysis and Visualization:

The project includes in-depth visualizations to explain model performance before and after applying PCA. This analytical approach is critical in understanding how each model handles the data's complexity and supports decision-making based on empirical evidence.
